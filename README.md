ğŸ§  Multi-Modal RAG Document Intelligence System

## ğŸ“Œ Overview

This project implements a Multi-Modal Retrieval-Augmented Generation (RAG) pipeline capable of extracting insights from complex PDF documents containing:

âœ” Text
âœ” Tables
âœ” Scanned images (OCR)

Users can upload a PDF through a Streamlit UI, ask natural language questions, and receive fact-grounded answers with citations to the document.
A summarization feature is also included to provide high-level document insights.

## ğŸš€ Features

| Feature | Description |
|--------|-------------|
| ğŸ“„ Multi-modal Ingestion | Extracts text, tables, and OCR text from images/scanned PDFs |
| ğŸ” Vector Search (FAISS) | Fast semantic Top-K retrieval for relevant document chunks |
| ğŸ§© Smart Chunking | Overlapping word-based chunking for improved context accuracy |
| ğŸ¤– Gemini LLM Integration | Generates grounded answers **only** using retrieved context with citations |
| ğŸ“Š Performance Metrics | Shows retrieval & generation latency + similarity scores |
| ğŸ“Œ Summarization Mode | Creates a **5-bullet policy briefing** from the document context |


## ğŸ§© System Architecture

**PDF Upload**  
â¬‡  
**Text & Table Extraction** (pdfplumber)  
+  
**OCR for Images/Scanned Pages** (Tesseract + Poppler)  
â¬‡  
**Smart Chunking** (overlapping word windows)  
â¬‡  
**Embeddings Generation**  
*SentenceTransformer â€” all-MiniLM-L6-v2*  
â¬‡  
**FAISS Vector Indexing**  
â¬‡  
**Top-K Semantic Retrieval**  
â¬‡  
**LLM Response Generation**  
*Gemini 2.5 Flash*  
â¬‡  
ğŸ“Œ **Grounded Answer with Page-Level Citations**


## ğŸ›  Tech Stack

| Component          | Tool |
|-------------------|------|
| LLM               | Gemini-2.5-Flash |
| Embedding Model   | all-MiniLM-L6-v2 |
| Vector Store      | FAISS |
| OCR               | Tesseract + Poppler |
| PDF Extraction    | pdfplumber, pdf2image |
| Frontend          | Streamlit |
| Language          | Python |


## 1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Add API Key (Important)

Create a .env file in root folder:

GEMINI_API_KEY=YOUR_KEY_HERE

3ï¸âƒ£ Run Streamlit
streamlit run app.py


Upload a PDF â†’ Ask questions â†’ View results with citations.

## ğŸ“ˆ Results & Performance Metrics

| Metric               | Value                |
|---------------------|---------------------|
| Avg Retrieval Time  | < 200 ms            |
| Avg Answer Generation | ~2â€“4 sec          |
| Modalities Supported | Text, Tables, OCR  |
| Citation Accuracy    | High               |

## ğŸ“Œ Performance tested using Qatar Economic PDF report.

## ğŸ“Œ Deliverables

âœ” Full Multi-Modal RAG pipeline

âœ” Streamlit demo application

âœ” Summarization bonus feature

âœ” Secure environment variable handling for API key

### ğŸ”’ Security

API keys are loaded from .env and not included in the repository.

.env
__pycache__/
*.pyc


are ignored via .gitignore.

## ğŸ“š Future Enhancements (Optional)

Cross-modal reranking (RRF)

Evaluation dashboard with quality metrics

Support for multiple PDF uploads

Chat history memory
